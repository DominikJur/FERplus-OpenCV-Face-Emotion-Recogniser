# ðŸ˜€ Facial Emotion Recognition

A real-time facial emotion recognition system that uses computer vision and deep learning to detect and classify facial expressions into seven basic emotions.

## Overview

This project uses a pre-trained ResNet18 model and OpenCV to recognize facial emotions in real-time from a webcam feed. The system can detect faces and classify emotions with reasonable accuracy.

### âœ¨ Features

- Real-time facial emotion detection from webcam
- Classification of 7 basic emotions: angry, disgust, fear, happy, neutral, sad, surprise
- Pre-trained ResNet18 model (61.81% accuracy on test set)
- User-friendly interface with emotion labels and confidence scores

## ðŸ“‚ Project Structure

```
â”œâ”€â”€ data/                  # Dataset directory
â”‚   â”œâ”€â”€ train/             # Training data organized by emotion folders
â”‚   â””â”€â”€ test/              # Test data organized by emotion folders
â”œâ”€â”€ models/                # Saved model weights
â”‚   â””â”€â”€ ResNet_epoch_66.pth # Pre-trained model
â”œâ”€â”€ notebooks/             # Jupyter notebooks
â”‚   â””â”€â”€ training.ipynb     # Model training notebook
â”œâ”€â”€ src/                   # Source code
â”‚   â”œâ”€â”€ dataset.py         # Dataset class and data loaders
â”‚   â”œâ”€â”€ face.py            # Face detection and emotion recognition
â”‚   â””â”€â”€ utils.py           # Utility functions
â”œâ”€â”€ main.py                # Main application script
â”œâ”€â”€ .gitignore             # Git ignore file
â”œâ”€â”€ LICENSE                # MIT License
â””â”€â”€ README.md              # Project documentation
```

## Requirements

- Python 3.6+
- PyTorch
- torchvision
- OpenCV
- NumPy
- Matplotlib
- scikit-learn
- PIL (Pillow)
- tqdm

## ðŸ”§ Installation

1. Clone the repository:
   ```
   git clone https://github.com/yourusername/facial-emotion-recognition.git
   cd facial-emotion-recognition
   ```

2. Create a virtual environment (optional but recommended):
   ```
   python -m venv venv
   source venv/bin/activate  # On Windows, use: venv\Scripts\activate
   ```

3. Install the dependencies:
   ```
   pip install torch torchvision opencv-python numpy matplotlib scikit-learn pillow tqdm
   ```

## ðŸš€ Usage

1. Run the main application to start facial emotion recognition with your webcam:
   ```
   python main.py
   ```

2. The application will open your webcam and start detecting faces and emotions in real-time.

3. Press 'q' to quit the application.

## Dataset

This project uses the FER2013 dataset or a similar facial emotion dataset organized in the following structure:

```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ angry/
â”‚   â”œâ”€â”€ disgust/
â”‚   â”œâ”€â”€ fear/
â”‚   â”œâ”€â”€ happy/
â”‚   â”œâ”€â”€ neutral/
â”‚   â”œâ”€â”€ sad/
â”‚   â””â”€â”€ surprise/
â””â”€â”€ test/
    â”œâ”€â”€ angry/
    â”œâ”€â”€ disgust/
    â”œâ”€â”€ fear/
    â”œâ”€â”€ happy/
    â”œâ”€â”€ neutral/
    â”œâ”€â”€ sad/
    â””â”€â”€ surprise/
```

Each subfolder contains facial images expressing the corresponding emotion.

## ðŸ§  Model

The system uses a pre-trained ResNet18 model modified for emotion classification:

- Base model: ResNet18 pre-trained on ImageNet
- Final layer replaced to output 7 emotion classes
- Trained on facial emotion dataset
- Current test accuracy: 61.81%

## Training

If you want to train the model yourself, you can run the Jupyter notebook:

```
jupyter notebook notebooks/training.ipynb
```

The notebook contains code to:
1. Load and preprocess the dataset
2. Create and configure the model
3. Train the model
4. Evaluate the model's performance

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- The ResNet18 implementation is based on the torchvision library
- Face detection uses OpenCV's Haar Cascade Classifier

## ðŸ¤” How It Works

1. Capture frames from webcam
2. Detect faces using OpenCV's Haar Cascade
3. Extract face region from image
4. Preprocess the face (resize, normalize)
5. Feed the face image to the ResNet18 model
6. Get emotion prediction and confidence score
7. Display result with bounding box and emotion label
