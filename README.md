# Facial Emotion Recognition ğŸ˜ŠğŸ˜ ğŸ˜¢

<div align="center">

![Python](https://img.shields.io/badge/Python-3.6+-blue.svg?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-1.7+-ee4c2c.svg?style=for-the-badge&logo=pytorch&logoColor=white)
![OpenCV](https://img.shields.io/badge/OpenCV-4.0+-5C3EE8.svg?style=for-the-badge&logo=opencv&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge)
![Accuracy](https://img.shields.io/badge/Accuracy-78%25+-yellow.svg?style=for-the-badge)

</div>

<p align="center">
  <img src="https://raw.githubusercontent.com/pytorch/pytorch.github.io/master/assets/images/pytorch-logo.png" width="120px"/>
  <img src="https://opencv.org/wp-content/uploads/2020/07/OpenCV_logo_black-2.png" width="120px"/>
</p>
## ğŸ“¸ Demo

![Facial Emotion Recognition - Happy](demo/happy.png)
*Detecting a happy expression with high confidence*

![Facial Emotion Recognition - Surprise](demo/surprise.png)
*Recognizing surprised emotion in real-time*

![Facial Emotion Recognition - Multiple](demo/multi.png)
*Detecting emotions for multiple people simultaneously*
## ğŸ“‹ Overview

A real-time facial emotion recognition system powered by deep learning. This application detects faces and classifies emotions in real-time video streams. Our model is trained on the RAF-DB dataset and achieves 78%+ accuracy, significantly outperforming our previous FER2013-based implementation.

## âœ¨ Features

- ğŸ¦ Real-time emotion recognition from webcam feed
- ğŸ§  Advanced ResNet-18 architecture pre-trained on ImageNet
- ğŸ­ Classification of 7 universal emotions (surprise, fear, disgust, happy, sad, angry, neutral)
- ğŸ“Š Live confidence scores for detected emotions
- âš¡ Optimized performance on standard hardware

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ data/                      # Dataset directory
â”‚   â””â”€â”€ DATASET/
â”‚       â”œâ”€â”€ test/              # Test data split by emotion classes
â”‚       â””â”€â”€ train/             # Training data split by emotion classes
â”œâ”€â”€ models/                    # Saved model weights
â”‚   â””â”€â”€ ResNet_epoch_50.pth    # Pre-trained model
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset.py             # Dataset loading and preprocessing
â”‚   â”œâ”€â”€ face.py                # Face detection and emotion recognition
â”‚   â””â”€â”€ utils.py               # Utility functions
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ training.ipynb         # Model training notebook
â”œâ”€â”€ main.py                    # Main application script
â”œâ”€â”€ README.md                  # Project documentation
â””â”€â”€ LICENSE                    # MIT License
```

## ğŸ“Š Dataset Information

This project uses the **RAF-DB** (Real-world Affective Faces Database), containing facial images labeled with 7 basic emotions.

### Dataset Structure

```
data/
â””â”€â”€ DATASET/
    â”œâ”€â”€ test/
    â”‚   â”œâ”€â”€ 1/  # surprise
    â”‚   â”œâ”€â”€ 2/  # fear
    â”‚   â”œâ”€â”€ 3/  # disgust
    â”‚   â”œâ”€â”€ 4/  # happy
    â”‚   â”œâ”€â”€ 5/  # sad
    â”‚   â”œâ”€â”€ 6/  # angry
    â”‚   â””â”€â”€ 7/  # neutral
    â””â”€â”€ train/
        â”œâ”€â”€ 1/
        â”œâ”€â”€ 2/
        â”œâ”€â”€ 3/
        â”œâ”€â”€ 4/
        â”œâ”€â”€ 5/
        â”œâ”€â”€ 6/
        â””â”€â”€ 7/
```

## ğŸš€ Installation & Setup

1. **Clone the repository:**
   ```bash
   git clone https://github.com/DominikJur/PyTorch-OpenCV-Facial-Expression-Recogniser.git
   cd PyTorch-OpenCV-Facial-Expression-Recogniser
   ```

2. **Create and activate a virtual environment:**
   ```bash
   python -m venv venv
   # On Windows:
   venv\Scripts\activate
   # On Unix or MacOS:
   source venv/bin/activate
   ```

3. **Install dependencies:**
   ```bash
   pip install torch torchvision opencv-python pillow scikit-learn matplotlib tqdm
   ```


## ğŸ® Usage

Run the main application for real-time webcam-based emotion recognition:

```bash
python main.py
```

- Press 'q' to exit the application

## ğŸ§  Model Architecture


- **Base Architecture**: ResNet-18 (pre-trained on ImageNet)
- **Training Methodology**:
  - Fine-tuned on RAF-DB dataset
  - 50+ epochs of training
  - Adam optimizer (lr=0.001)
  - Cross-Entropy Loss function
- **Input Processing**:
  - 48Ã—48 RGB images
  - Data augmentation: horizontal flips, rotations, normalization
- **Output**: 7-class emotion classification with confidence scores

## ğŸ“ˆ Performance Metrics

| Metric | Value |
|--------|-------|
| Accuracy | 78%+ |
| Inference Time | Real-time |
| Model Size | ~44MB |


## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- RAF-DB dataset providers
- PyTorch and OpenCV communities
- Academic research on facial emotion recognition

---

<div align="center">
  <b>Made with â¤ï¸ by Dominik Jur</b>
</div>
